{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|count(StockCode)|\n",
      "+----------------+\n",
      "|541909          |\n",
      "+----------------+\n",
      "\n",
      "+-------------------------+\n",
      "|count(DISTINCT StockCode)|\n",
      "+-------------------------+\n",
      "|4070                     |\n",
      "+-------------------------+\n",
      "\n",
      "+--------------------------------+\n",
      "|approx_count_distinct(StockCode)|\n",
      "+--------------------------------+\n",
      "|3364                            |\n",
      "+--------------------------------+\n",
      "\n",
      "+----------------+---------------+\n",
      "|first(StockCode)|last(StockCode)|\n",
      "+----------------+---------------+\n",
      "|85123A          |22138          |\n",
      "+----------------+---------------+\n",
      "\n",
      "+-------------+-------------+\n",
      "|max(Quantity)|min(Quantity)|\n",
      "+-------------+-------------+\n",
      "|80995        |-80995       |\n",
      "+-------------+-------------+\n",
      "\n",
      "+-------------+----------------------+\n",
      "|sum(Quantity)|sum(DISTINCT Quantity)|\n",
      "+-------------+----------------------+\n",
      "|5176450      |29310                 |\n",
      "+-------------+----------------------+\n",
      "\n",
      "+----------------+----------------+----------------+\n",
      "|avg             |avg_quantity    |mean            |\n",
      "+----------------+----------------+----------------+\n",
      "|9.55224954743324|9.55224954743324|9.55224954743324|\n",
      "+----------------+----------------+----------------+\n",
      "\n",
      "+----------+---------+-----+\n",
      "|CustomerID|InvoiceNo|count|\n",
      "+----------+---------+-----+\n",
      "|     15955|   536635|   20|\n",
      "|     17850|   536690|   17|\n",
      "|     15426|   537196|   86|\n",
      "|     12494|  C539114|    1|\n",
      "|     14723|   539321|   47|\n",
      "|     16931|   539414|   40|\n",
      "|     13458|  C539838|    1|\n",
      "|     15039|   540024|    1|\n",
      "|     12601|   540769|    9|\n",
      "|     17609|   541265|  100|\n",
      "|     13328|   542397|   17|\n",
      "|     17431|   542613|   43|\n",
      "|     13394|   543054|   16|\n",
      "|     13819|   543658|   12|\n",
      "|     17811|   543801|    9|\n",
      "|     16422|   544769|    5|\n",
      "|     16722|   544914|   15|\n",
      "|      null|   536596|    6|\n",
      "|      null|   537252|    1|\n",
      "|      null|   538041|    1|\n",
      "+----------+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------+-----------------+---------------+\n",
      "|InvoiceNo|count_of_quantity|count(Quantity)|\n",
      "+---------+-----------------+---------------+\n",
      "|536596   |6                |6              |\n",
      "+---------+-----------------+---------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+---------+-------------+--------------------+\n",
      "|InvoiceNo|avg(Quantity)|stddev_pop(Quantity)|\n",
      "+---------+-------------+--------------------+\n",
      "|536596   |1.5          |1.1180339887498947  |\n",
      "+---------+-------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, countDistinct, approx_count_distinct, first, last, max, min, sum, sumDistinct, avg, mean, collect_list, collect_set, expr, stddev_pop\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"chapter7\").getOrCreate()\n",
    "\n",
    "df = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(\"retail-data/all/*.csv\").coalesce(5)\n",
    "df.cache()\n",
    "df.createOrReplaceTempView(\"dfTable\")\n",
    "\n",
    "df.count()\n",
    "\n",
    "df.select(count(\"StockCode\")).show(1, False)\n",
    "\n",
    "df.select(countDistinct(\"StockCode\")).show(1, False)\n",
    "\n",
    "df.select(approx_count_distinct(\"StockCode\", 0.1)).show(1, False)\n",
    "\n",
    "df.select(first(\"StockCode\"), last(\"StockCode\")).show(1, False)\n",
    "\n",
    "df.select(max(\"Quantity\"), min(\"Quantity\")).show(1, False)\n",
    "\n",
    "df.select(sum(\"Quantity\"), sumDistinct(\"Quantity\")).show(1, False)\n",
    "\n",
    "df.select(sum(\"Quantity\").alias(\"total_sum\"), count(\"Quantity\").alias(\"number_of_quantities\"), avg(\"Quantity\").alias(\"avg_quantity\"), mean(\"Quantity\").alias(\"mean\")).selectExpr(\"total_sum/number_of_quantities as avg\", \"avg_quantity\", \"mean\").show(10, False)\n",
    "\n",
    "# df.select(collect_list(\"Country\"), collect_set(\"Country\")).show(1, False)\n",
    "\n",
    "df.groupBy(\"CustomerID\", \"InvoiceNo\").count().show()\n",
    "\n",
    "df.groupBy(\"InvoiceNo\").agg(count(\"Quantity\").alias(\"count_of_quantity\"), expr(\"count(Quantity)\")).show(1, False)\n",
    "\n",
    "df.groupBy(\"InvoiceNo\").agg(expr(\"avg(Quantity)\"), expr(\"stddev_pop(Quantity)\")).show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+--------+------------+-----------------+-------------------+\n",
      "|CustomerId|date|Quantity|quantityRank|quantityDenseRank|maxPurchaseQuantity|\n",
      "+----------+----+--------+------------+-----------------+-------------------+\n",
      "|     12346|null|   74215|           1|                1|              74215|\n",
      "|     12346|null|  -74215|           2|                2|              74215|\n",
      "|     12347|null|     240|           1|                1|                240|\n",
      "|     12347|null|      48|           2|                2|                240|\n",
      "|     12347|null|      36|           3|                3|                240|\n",
      "|     12347|null|      36|           3|                3|                240|\n",
      "|     12347|null|      36|           3|                3|                240|\n",
      "|     12347|null|      36|           3|                3|                240|\n",
      "|     12347|null|      36|           3|                3|                240|\n",
      "|     12347|null|      36|           3|                3|                240|\n",
      "|     12347|null|      30|           9|                4|                240|\n",
      "|     12347|null|      24|          10|                5|                240|\n",
      "|     12347|null|      24|          10|                5|                240|\n",
      "|     12347|null|      24|          10|                5|                240|\n",
      "|     12347|null|      24|          10|                5|                240|\n",
      "|     12347|null|      24|          10|                5|                240|\n",
      "|     12347|null|      24|          10|                5|                240|\n",
      "|     12347|null|      24|          10|                5|                240|\n",
      "|     12347|null|      24|          10|                5|                240|\n",
      "|     12347|null|      24|          10|                5|                240|\n",
      "+----------+----+--------+------------+-----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_date, desc,dense_rank, rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "dfWithDate = df.withColumn(\"date\", to_date(col(\"InvoiceDate\")))\n",
    "dfWithDate.createOrReplaceTempView(\"dfWithDate\")\n",
    "\n",
    "windowSpec = Window\\\n",
    "  .partitionBy(\"CustomerId\", \"date\")\\\n",
    "  .orderBy(desc(\"Quantity\"))\\\n",
    "  .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "maxPurchase = max(\"Quantity\").over(windowSpec)\n",
    "\n",
    "purchaseDenseRank = dense_rank().over(windowSpec)\n",
    "purchaseRank = rank().over(windowSpec)\n",
    "\n",
    "dfWithDate.where(\"CustomerId IS NOT NULL\").orderBy(\"CustomerId\")\\\n",
    "  .select(\n",
    "    col(\"CustomerId\"),\n",
    "    col(\"date\"),\n",
    "    col(\"Quantity\"),\n",
    "    purchaseRank.alias(\"quantityRank\"),\n",
    "    purchaseDenseRank.alias(\"quantityDenseRank\"),\n",
    "    maxPurchase.alias(\"maxPurchaseQuantity\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|customerId|stockCode|sum(Quantity)|\n",
      "+----------+---------+-------------+\n",
      "|18287     |85173    |48           |\n",
      "|18287     |85040A   |48           |\n",
      "|18287     |85039B   |120          |\n",
      "|18287     |85039A   |96           |\n",
      "|18287     |84920    |4            |\n",
      "|18287     |84584    |6            |\n",
      "|18287     |84507C   |6            |\n",
      "|18287     |72351B   |24           |\n",
      "|18287     |72351A   |24           |\n",
      "|18287     |72349B   |60           |\n",
      "+----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+----------+---------+-------------+\n",
      "|customerId|stockCode|sum(Quantity)|\n",
      "+----------+---------+-------------+\n",
      "|18287     |85173    |48           |\n",
      "|18287     |85040A   |48           |\n",
      "|18287     |85039B   |120          |\n",
      "|18287     |85039A   |96           |\n",
      "|18287     |84920    |4            |\n",
      "|18287     |84584    |6            |\n",
      "|18287     |84507C   |6            |\n",
      "|18287     |72351B   |24           |\n",
      "|18287     |72351A   |24           |\n",
      "|18287     |72349B   |60           |\n",
      "+----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+----+-------+--------------+\n",
      "|Date|Country|total_quantity|\n",
      "+----+-------+--------------+\n",
      "|null|   null|       5176450|\n",
      "|null|   null|       5176450|\n",
      "+----+-------+--------------+\n",
      "\n",
      "+----+--------------------+--------------+\n",
      "|Date|             Country|total_quantity|\n",
      "+----+--------------------+--------------+\n",
      "|null|  European Community|           497|\n",
      "|null|      Czech Republic|           592|\n",
      "|null|           Lithuania|           652|\n",
      "|null|              Canada|          2763|\n",
      "|null|              France|        110480|\n",
      "|null|                null|       5176450|\n",
      "|null|             Iceland|          2458|\n",
      "|null|      United Kingdom|       4263829|\n",
      "|null|             Lebanon|           386|\n",
      "|null|             Germany|        117448|\n",
      "|null|              Sweden|         35637|\n",
      "|null|              Greece|          1556|\n",
      "|null|             Finland|         10666|\n",
      "|null|             Denmark|          8188|\n",
      "|null|                null|       5176450|\n",
      "|null|            Portugal|         16180|\n",
      "|null|             Austria|          4827|\n",
      "|null|     Channel Islands|          9479|\n",
      "|null|           Singapore|          5234|\n",
      "|null|United Arab Emirates|           982|\n",
      "+----+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----+-------+-------------+\n",
      "|Date|Country|sum(Quantity)|\n",
      "+----+-------+-------------+\n",
      "|null|   null|      5176450|\n",
      "|null|   null|      5176450|\n",
      "+----+-------+-------------+\n",
      "\n",
      "+----+-------+-------------+\n",
      "|Date|Country|sum(Quantity)|\n",
      "+----+-------+-------------+\n",
      "|null|   null|      5176450|\n",
      "|null|   null|      5176450|\n",
      "+----+-------+-------------+\n",
      "\n",
      "+----------+---------+-------------+-------------+\n",
      "|customerId|stockCode|grouping_id()|sum(Quantity)|\n",
      "+----------+---------+-------------+-------------+\n",
      "|     17908|    20713|            0|            1|\n",
      "|     17920|    22759|            0|            6|\n",
      "|     17897|    22867|            0|            5|\n",
      "|     14729|    22916|            0|            1|\n",
      "|     15012|   47599A|            0|            1|\n",
      "|     15525|    22453|            0|            1|\n",
      "|     12433|    22615|            0|           96|\n",
      "|     16456|   85099C|            0|           80|\n",
      "|     17873|   51014C|            0|           36|\n",
      "|     13777|    84050|            0|          420|\n",
      "|     12947|    22637|            0|           12|\n",
      "|     17017|    21914|            0|          252|\n",
      "|     14390|    22418|            0|            2|\n",
      "|     16916|    21504|            0|           12|\n",
      "|     16510|    22169|            0|            2|\n",
      "|     16781|    21781|            0|            0|\n",
      "|     15574|    21984|            0|            1|\n",
      "|     18239|    21364|            0|            2|\n",
      "|     12682|    22892|            0|           36|\n",
      "|     17238|    20749|            0|            1|\n",
      "+----------+---------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import grouping_id\n",
    "\n",
    "dfNoNull = dfWithDate.drop()\n",
    "dfNoNull.createOrReplaceTempView(\"dfNoNull\")\n",
    "\n",
    "spark.sql(\"SELECT CustomerId, stockCode, sum(Quantity) FROM dfNoNull GROUP BY customerId, stockCode GROUPING SETS((customerId, stockCode)) ORDER BY CustomerId DESC, stockCode DESC\").show(10, False)\n",
    "\n",
    "spark.sql(\"SELECT CustomerId, stockCode, sum(Quantity) FROM dfNoNull GROUP BY customerId, stockCode GROUPING SETS((customerId, stockCode),()) ORDER BY CustomerId DESC, stockCode DESC\").show(10, False)\n",
    "\n",
    "rolledUpDF = dfNoNull.rollup(\"Date\", \"Country\").agg(sum(\"Quantity\"))\\\n",
    "  .selectExpr(\"Date\", \"Country\", \"`sum(Quantity)` as total_quantity\")\\\n",
    "  .orderBy(\"Date\")\n",
    "rolledUpDF.where(expr(\"Country is NULL\")).show()\n",
    "rolledUpDF.where(\"Date is NULL\").show()\n",
    "# rolledUpDF.show()\n",
    "\n",
    "\n",
    "dfNoNull.cube(\"Date\", \"Country\").agg(sum(col(\"Quantity\")))\\\n",
    "  .select(\"Date\", \"Country\", \"sum(Quantity)\").orderBy(\"Date\").where(\"Country is NULL\").show()\n",
    "\n",
    "dfNoNull.cube(\"Date\", \"Country\").agg(grouping_id(), sum(col(\"Quantity\")))\\\n",
    "  .select(\"Date\", \"Country\", \"sum(Quantity)\").orderBy(\"Date\").where(\"Country is NULL\").show()\n",
    "\n",
    "dfNoNull.cube(\"customerId\", \"stockCode\").agg(grouping_id(), sum(\"Quantity\"))\\\n",
    ".orderBy(expr(\"grouping_id()\"))\\\n",
    ".show()\n",
    "\n",
    "pivoted = dfWithDate.groupBy(\"date\").pivot(\"Country\").sum()\n",
    "\n",
    "# pivoted.where(\"date > '2011-12-05'\").select(\"date\" ,\"`USA_sum(CusomterID)`\").show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
